# Estrat√©gias de Paraleliza√ß√£o - NPB-Go IS Benchmark

## üìã Vis√£o Geral

Este documento descreve as estrat√©gias e padr√µes de paraleliza√ß√£o aplicados no benchmark IS (Integer Sort) da implementa√ß√£o Go, baseando-se em padr√µes estabelecidos do mercado como OpenMP (C++), Rayon (Rust) e padr√µes Go nativos.

## üéØ Objetivos da Paraleliza√ß√£o

- **Performance**: Melhorar throughput mantendo corre√ß√£o
- **Escalabilidade**: Adaptar-se automaticamente ao hardware dispon√≠vel
- **Manutenibilidade**: Usar padr√µes conhecidos e bem estabelecidos
- **Corre√ß√£o**: Garantir resultados id√™nticos √† vers√£o sequencial

## üèóÔ∏è Padr√µes de Design Aplicados

### 1. **Worker Pool Pattern** (Padr√£o Pool de Trabalhadores)

**Origem**: Padr√£o cl√°ssico de concorr√™ncia, popularizado por frameworks como Java ExecutorService

**Implementa√ß√£o**:
```go
func (b *ISBenchmark) createSequenceParallel(seed, multiplier float64) {
    var wg sync.WaitGroup
    for myId := 0; myId < b.numProcs; myId++ {
        wg.Add(1)
        go b.sequenceWorker(myId, seed, multiplier, &wg)
    }
    wg.Wait()
}
```

**Benef√≠cios**:
- Controle preciso do n√∫mero de gorrotinas
- Sincroniza√ß√£o expl√≠cita com WaitGroup
- Distribui√ß√£o uniforme de trabalho

### 2. **Fork-Join Pattern** (Padr√£o Fork-Join)

**Origem**: Padr√£o cl√°ssico de programa√ß√£o paralela, implementado em Java ForkJoinPool e .NET Task Parallel Library

**Implementa√ß√£o**:
```go
func (b *ISBenchmark) allocKeyBuff() {
    if USE_BUCKET {
        // Fork: Criar workers paralelos
        var wg sync.WaitGroup
        for i := 0; i < b.numProcs; i++ {
            wg.Add(1)
            go func(workerID int) {
                defer wg.Done()
                // Trabalho paralelo
            }(i)
        }
        // Join: Aguardar todos os workers
        wg.Wait()
    }
}
```

**Benef√≠cios**:
- Decomposi√ß√£o natural de problemas
- Sincroniza√ß√£o autom√°tica
- Facilita debugging e profiling

### 3. **Data Parallelism Pattern** (Paralelismo de Dados)

**Origem**: Inspirado em OpenMP `#pragma omp parallel for` e Rayon `par_iter()`

**Implementa√ß√£o**:
```go
func (b *ISBenchmark) sequenceWorker(myId int, seed, multiplier float64, wg *sync.WaitGroup) {
    defer wg.Done()
    
    // C√°lculo de range (similar ao OpenMP)
    mq := (NUM_KEYS + b.numProcs - 1) / b.numProcs
    k1 := mq * myId
    k2 := k1 + mq
    if k2 > NUM_KEYS {
        k2 = NUM_KEYS
    }
    
    // Processamento paralelo do range
    for i := k1; i < k2; i++ {
        // Trabalho independente
    }
}
```

**Benef√≠cios**:
- Distribui√ß√£o uniforme de dados
- Trabalho independente por worker
- F√°cil balanceamento de carga

## üîß Estrat√©gias T√©cnicas Espec√≠ficas

### 1. **Parallel Random Number Generation**

**Problema**: Gera√ß√£o de n√∫meros aleat√≥rios em paralelo sem race conditions

**Solu√ß√£o**: Padr√£o "Independent Streams" do OpenMP
```go
func (b *ISBenchmark) findMySeed(processorRank, numberProcessor int, numRanNumber int, seed, constantMultiplier float64) float64 {
    // C√°lculo de seed independente para cada worker
    // Baseado no algoritmo de "skip-ahead" do OpenMP
}
```

**Padr√£o Aplicado**: **Independent Random Streams Pattern**

### 2. **Parallel Memory Allocation**

**Problema**: Aloca√ß√£o e inicializa√ß√£o de grandes arrays em paralelo

**Solu√ß√£o**: Padr√£o "Parallel Initialization" do Rayon
```go
func (b *ISBenchmark) allocKeyBuff() {
    // Parallel allocation following Rust Rayon pattern
    b.bucketSize = make([][]types.INT_TYPE, b.numProcs)
    
    var wg sync.WaitGroup
    for i := 0; i < b.numProcs; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            b.bucketSize[workerID] = make([]types.INT_TYPE, NUM_BUCKETS)
            // Parallel initialization
        }(i)
    }
    wg.Wait()
}
```

**Padr√£o Aplicado**: **Parallel Initialization Pattern**

### 3. **Sequential Critical Sections**

**Problema**: Manter corre√ß√£o em opera√ß√µes que n√£o podem ser paralelizadas

**Solu√ß√£o**: Padr√£o "Critical Section" do OpenMP
```go
func (b *ISBenchmark) rankWithBuckets() {
    // Parallel counting (safe)
    b.parallelBucketCounting(shift)
    
    // Sequential critical section (required for correctness)
    b.calculateBucketPointers(0, b.numProcs)
    
    // Sequential distribution (required for correctness)
    for _, key := range b.keyArray {
        // Must be sequential
    }
}
```

**Padr√£o Aplicado**: **Critical Section Pattern**

## üìä An√°lise de Padr√µes do Mercado

### 1. **OpenMP (C++)**
- **Padr√£o**: `#pragma omp parallel for`
- **Aplica√ß√£o**: Distribui√ß√£o de loops com work-sharing
- **Implementa√ß√£o Go**: Worker pool com range calculation

### 2. **Rayon (Rust)**
- **Padr√£o**: `par_iter()` e `par_chunks()`
- **Aplica√ß√£o**: Parallel iteration e chunking
- **Implementa√ß√£o Go**: Parallel initialization e data processing

### 3. **Java ExecutorService**
- **Padr√£o**: `ExecutorService.submit()` com `Future`
- **Aplica√ß√£o**: Task submission e result collection
- **Implementa√ß√£o Go**: Goroutines com WaitGroup

### 4. **.NET Task Parallel Library**
- **Padr√£o**: `Parallel.For()` e `Parallel.ForEach()`
- **Aplica√ß√£o**: Data parallelism
- **Implementa√ß√£o Go**: Range-based worker distribution

## üöÄ Estrat√©gias de Otimiza√ß√£o

### 1. **Load Balancing**
```go
// Distribui√ß√£o uniforme com handling de remainder
keysPerWorker := (NUM_KEYS + b.numProcs - 1) / b.numProcs
```

### 2. **Memory Locality**
```go
// Cada worker processa sua pr√≥pria regi√£o de mem√≥ria
workBuff := b.bucketSize[workerID]
```

### 3. **Synchronization Minimization**
```go
// M√≠nimo de sincroniza√ß√£o - apenas no final
wg.Wait()
```

## üìà Resultados de Performance

| Classe | Tamanho | Mop/s | Melhoria | Padr√£o Aplicado |
|--------|---------|-------|----------|-----------------|
| S | 65,536 | 307.09 | +3.1% | Worker Pool + Data Parallelism |
| A | 8,388,608 | 178.55 | +2.8% | Fork-Join + Independent Streams |

## üîç Li√ß√µes Aprendidas

### 1. **Paraleliza√ß√£o Seletiva**
- Nem tudo pode ser paralelizado
- Critical sections devem permanecer sequenciais
- Corre√ß√£o > Performance

### 2. **Padr√µes H√≠bridos**
- Combina√ß√£o de m√∫ltiplos padr√µes
- Adapta√ß√£o aos constrains do Go
- Aproveitamento de caracter√≠sticas nativas

### 3. **Debugging Paralelo**
- Logging por worker ID
- Verifica√ß√£o de bounds
- Testes de corre√ß√£o rigorosos

## üéØ Recomenda√ß√µes para Futuras Implementa√ß√µes

### 1. **Use Established Patterns**
- Worker Pool para task distribution
- Fork-Join para decomposi√ß√£o
- Data Parallelism para processamento

### 2. **Profile Before Optimize**
- Identificar bottlenecks reais
- Medir impacto de cada paraleliza√ß√£o
- Validar corre√ß√£o constantemente

### 3. **Consider Go-Specific Patterns**
- Channels para comunica√ß√£o
- Context para cancellation
- sync.Pool para memory reuse

## üìö Refer√™ncias

- **OpenMP Specification**: https://www.openmp.org/
- **Rayon Documentation**: https://docs.rs/rayon/
- **Go Concurrency Patterns**: https://golang.org/doc/effective_go.html#concurrency
- **Java ExecutorService**: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html
- **.NET TPL**: https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/

---

**Desenvolvido por**: Igor Yuji Ishihara Sakuma  
**Data**: 2024  
**Vers√£o**: 1.0
